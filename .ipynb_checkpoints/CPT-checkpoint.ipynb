{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PredictionTree import *\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class CPT():\n",
    "\n",
    "    alphabet = None # A set of all unique items in the entire data file\n",
    "    root = None # Root node of the Prediction Tree\n",
    "    II = None # Inverted Index dictionary, where key : unique item, value : set of sequences containing this item\n",
    "    LT = None # A Lookup table dictionary, where key : id of a sequence(row), value: leaf node of a Prediction Tree\n",
    "\n",
    "    def __init__(self):\n",
    "        self.alphabet = set()\n",
    "        self.root = PredictionTree()\n",
    "        self.II = {}\n",
    "        self.LT = {}\n",
    "\n",
    "    def load_files(self,train_dir,test_dir = None):\n",
    "\n",
    "        \"\"\"\n",
    "        This function reads in the wide csv file of sequences separated by commas and returns a list of list of those\n",
    "        sequences. The sequences are defined as below.\n",
    "\n",
    "        seq1 = A,B,C,D\n",
    "        seq2  B,C,E\n",
    "\n",
    "        Returns: [[A,B,C,D],[B,C,E]]\n",
    "        \"\"\"\n",
    "        \n",
    "        data = [] # List of list containing the entire sequence data using which the model will be trained.\n",
    "        target = [] # List of list containing the test sequences whose next n items are to be predicted\n",
    "        \n",
    "        for path in os.listdir(train_dir):\n",
    "            with open(os.path.join(train_dir,path)) as train_file:\n",
    "                training_json = json.loads(train_file.read())\n",
    "                for token, next_tokens in training_json[0][\"References\"].items():\n",
    "                    for next_token, properties in next_tokens.items():\n",
    "                        data.append([token, next_token])\n",
    "            \n",
    "        for path in os.listdir(test_dir):\n",
    "            with open(os.path.join(test_dir,path)) as test_file:\n",
    "                test_json = json.loads(test_file.read())\n",
    "                for token, next_tokens in test_json[0][\"References\"].items():\n",
    "                    for next_token, properties in next_tokens.items():\n",
    "                        if next_token == \"__TOKEN_TO_PREDICT__\":\n",
    "                            data.append([token])\n",
    "                            target.append([token])\n",
    "                        data.append([token, next_token])\n",
    "                        target.append([token, next_token])\n",
    "        \n",
    "        return data, target\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    def train(self, data):\n",
    "\n",
    "        \"\"\"\n",
    "        This functions populates the Prediction Tree, Inverted Index and LookUp Table for the algorithm.\n",
    "\n",
    "        Input: The list of list training data\n",
    "        Output : Boolean True\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        cursornode = self.root\n",
    "        \n",
    "        for seqid, row in enumerate(data):\n",
    "            for element in row:\n",
    "\n",
    "                # adding to the Prediction Tree\n",
    "\n",
    "                if cursornode.hasChild(element) == False:\n",
    "                    cursornode.addChild(element)\n",
    "                    cursornode = cursornode.getChild(element)\n",
    "\n",
    "                else:\n",
    "                    cursornode = cursornode.getChild(element)\n",
    "\n",
    "                # Adding to the Inverted Index\n",
    "\n",
    "                if self.II.get(element) is None:\n",
    "                    self.II[element] = set()\n",
    "\n",
    "                self.II[element].add(seqid)\n",
    "                \n",
    "                self.alphabet.add(element)\n",
    "\n",
    "            self.LT[seqid] = cursornode\n",
    "\n",
    "            cursornode = self.root\n",
    "            \n",
    "        return True\n",
    "\n",
    "    def score(self, counttable, key, length, target_size, number_of_similar_sequences, number_items_counttable):\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        This function is the main workhorse and calculates the score to be populated against an item. Items are predicted\n",
    "        using this score.\n",
    "\n",
    "        Output: Returns a counttable dictionary which stores the score against items. This counttable is specific for a \n",
    "        particular row or a sequence and therefore re-calculated at each prediction.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        weight_level = 1/number_of_similar_sequences\n",
    "        weight_distance = 1/number_items_counttable\n",
    "        score = 1 + weight_level + weight_distance* 0.001\n",
    "        \n",
    "        if counttable.get(key) is None:\n",
    "            counttable[key] = score\n",
    "        else:\n",
    "            counttable[key] = score * counttable.get(key)\n",
    "            \n",
    "        return counttable\n",
    "\n",
    "    def predict(self,data,target,k, n=1): \n",
    "        \n",
    "        \"\"\"\n",
    "        Here target is the test dataset in the form of list of list,\n",
    "        k is the number of last elements that will be used to find similar sequences and,\n",
    "        n is the number of predictions required.\n",
    "\n",
    "        Input: training list of list, target list of list, k,n\n",
    "\n",
    "        Output: max n predictions for each sequence\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for each_target in tqdm(target):\n",
    "            each_target = each_target[-k:]\n",
    "            \n",
    "            intersection = set(range(0,len(data)))\n",
    "            \n",
    "            for element in each_target:\n",
    "                if self.II.get(element) is None:\n",
    "                    continue\n",
    "                intersection = intersection & self.II.get(element)\n",
    "            \n",
    "            similar_sequences = []\n",
    "            \n",
    "            for element in intersection:\n",
    "                currentnode = self.LT.get(element)\n",
    "                tmp = []\n",
    "                while currentnode.Item is not None:\n",
    "                    tmp.append(currentnode.Item)\n",
    "                    currentnode = currentnode.Parent\n",
    "                similar_sequences.append(tmp)\n",
    "                \n",
    "            for sequence in similar_sequences:\n",
    "                sequence.reverse()\n",
    "                \n",
    "            counttable = {}\n",
    "\n",
    "            for  sequence in similar_sequences:\n",
    "                try:\n",
    "                    index = next(i for i,v in zip(range(len(sequence)-1, 0, -1), reversed(sequence)) if v == each_target[-1])\n",
    "                except:\n",
    "                    index = None\n",
    "                if index is not None:\n",
    "                    count = 1\n",
    "                    for element in sequence[index+1:]:\n",
    "                        if element in each_target:\n",
    "                            continue\n",
    "                            \n",
    "                        counttable = self.score(counttable,element,len(each_target),len(each_target),len(similar_sequences),count)\n",
    "                        count+=1\n",
    "\n",
    "\n",
    "            pred = self.get_n_largest(counttable,n)\n",
    "            predictions.append(pred)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def get_n_largest(self,dictionary,n):\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        A small utility to obtain top n keys of a Dictionary based on their values.\n",
    "\n",
    "        \"\"\"\n",
    "        largest = sorted(dictionary.items(), key = lambda t: t[1], reverse=True)[:n]\n",
    "        return [key for key,_ in largest]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
