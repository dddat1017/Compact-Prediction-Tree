{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionTree():\n",
    "    \n",
    "    Item = None\n",
    "    Parent = None\n",
    "    Children = None\n",
    "    \n",
    "    def __init__(self,itemValue=None):\n",
    "        self.Item = itemValue\n",
    "        self.Children = []\n",
    "        self.Parent = None\n",
    "        \n",
    "    def addChild(self, child):\n",
    "        newchild = PredictionTree(child)\n",
    "        newchild.Parent = self\n",
    "        self.Children.append(newchild)\n",
    "        \n",
    "    def getChild(self,target):\n",
    "        for chld in self.Children:\n",
    "            if chld.Item == target:\n",
    "                return chld\n",
    "        return None\n",
    "    \n",
    "    def getChildren(self):\n",
    "        return self.Children\n",
    "        \n",
    "    def hasChild(self,target):\n",
    "        found = self.getChild(target)\n",
    "        if found is not None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def removeChild(self,child):\n",
    "        for chld in self.Children:\n",
    "            if chld.Item==child:\n",
    "                self.Children.remove(chld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "class CPT():\n",
    "\n",
    "    #alphabet = None # A set of all unique items in the entire data file\n",
    "    #root = None # Root node of the Prediction Tree\n",
    "    II = None # Inverted Index dictionary, where key : unique item, value : set of sequences containing this item\n",
    "    LT = None # A Lookup table dictionary, where key : id of a sequence(row), value: leaf node of a Prediction Tree\n",
    "\n",
    "    def __init__(self):\n",
    "        #self.alphabet = set()\n",
    "        #self.root = PredictionTree()\n",
    "        self.II = {}\n",
    "        self.LT = {}\n",
    "\n",
    "    def load_files(self, train_dir, test_dir = None):\n",
    "\n",
    "        \"\"\"\n",
    "        seq1 = A,B,C,D\n",
    "        seq2  B,C,E\n",
    "\n",
    "        Returns: [[A,B,C,D],[B,C,E]]\n",
    "        \"\"\"\n",
    "        \n",
    "        data = [] # List of list containing the entire sequence data using which the model will be trained\n",
    "        target = [] # List of list containing the test sequences whose next n items are to be predicted\n",
    "        seqid = 0\n",
    "        \n",
    "        for path in os.listdir(train_dir):\n",
    "            with open(os.path.join(train_dir,path)) as train_file:\n",
    "                training_json = json.loads(train_file.read())\n",
    "                for token, next_tokens in training_json[0][\"References\"].items():\n",
    "                    for next_token, properties in next_tokens.items():\n",
    "                        data.append([token, next_token, seqid])\n",
    "                        self.LT[seqid] = next_token #NEW\n",
    "                        seqid += 1 #NEW\n",
    "        \n",
    "        for path in os.listdir(test_dir):\n",
    "            with open(os.path.join(test_dir,path)) as test_file:\n",
    "                test_json = json.loads(test_file.read())\n",
    "                for token, next_tokens in test_json[0][\"References\"].items():\n",
    "                    for next_token, properties in next_tokens.items():\n",
    "                        if next_token == \"__TOKEN_TO_PREDICT__\":\n",
    "                            target.append([path, token])\n",
    "                        else: \n",
    "                            data.append([token, next_token, seqid])\n",
    "                            self.LT[seqid] = next_token #NEW\n",
    "                            seqid += 1 #NEW\n",
    "                            \n",
    "        \n",
    "        #print(\"Data is\", data)\n",
    "        #print(\"Target is\", target)\n",
    "        \n",
    "        return data, target\n",
    "\n",
    "    def train(self, data):\n",
    "\n",
    "        \"\"\"\n",
    "        This functions populates the Prediction Tree, Inverted Index and LookUp Table for the algorithm.\n",
    "\n",
    "        Input: The list of list training data\n",
    "        Output : Boolean True\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        cursornode = self.root\n",
    "        \n",
    "        for seqid, row in enumerate(data):\n",
    "            for element in row:\n",
    "\n",
    "                # Adding to the Prediction Tree\n",
    "\n",
    "                if cursornode.hasChild(element) == False:\n",
    "                    cursornode.addChild(element)\n",
    "                    cursornode = cursornode.getChild(element)\n",
    "                else:\n",
    "                    cursornode = cursornode.getChild(element)\n",
    "\n",
    "                # Adding to the Inverted Index\n",
    "\n",
    "                if self.II.get(element) is None:\n",
    "                    self.II[element] = set()\n",
    "\n",
    "                self.II[element].add(seqid)\n",
    "                \n",
    "                self.alphabet.add(element)\n",
    "\n",
    "            # Adding to the LookUp table\n",
    "            \n",
    "            self.LT[seqid] = cursornode\n",
    "\n",
    "            cursornode = self.root\n",
    "        \"\"\"\n",
    "        \n",
    "        for row in data:\n",
    "            for element in row[:-1]:\n",
    "                if self.II.get(element) is None:\n",
    "                    self.II[element] = set()\n",
    "            \n",
    "                self.II[element].add(row[2])\n",
    "            \n",
    "        return True\n",
    "\n",
    "    def score(self, counttable, key, number_of_similar_sequences, number_items_counttable):\n",
    "\n",
    "        \"\"\"\n",
    "        This function is the main workhorse and calculates the score to be populated against an item. Items are predicted\n",
    "        using this score.\n",
    "\n",
    "        Output: Returns a counttable dictionary which stores the score against items. This counttable is specific for a \n",
    "        particular row or a sequence and therefore re-calculated at each prediction.\n",
    "        \"\"\"\n",
    "\n",
    "        weight_level = 1/number_of_similar_sequences\n",
    "        weight_distance = 1/(number_items_counttable+1)\n",
    "        score = 1 + weight_level + weight_distance * 0.001\n",
    "        \n",
    "        if counttable.get(key) is None:\n",
    "            counttable[key] = score\n",
    "        else:\n",
    "            counttable[key] = (score * counttable.get(key))\n",
    "            \n",
    "        return counttable\n",
    "\n",
    "    def predict(self, target, n): \n",
    "        \n",
    "        \"\"\"\n",
    "        Here target is the test dataset in the form of list of list and\n",
    "        n is the number of predictions required.\n",
    "\n",
    "        Input: target list of list, n\n",
    "\n",
    "        Output: list of [[NameOfFile,pred1,pred2,pred3,pred4,pred5], ...]\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for num, sequence in enumerate(target):\n",
    "            similar_sequences = []\n",
    "            consequents = []\n",
    "            counttable = {}\n",
    "            \n",
    "            \"\"\"\n",
    "            for element in sequence:\n",
    "                if self.II.get(element) is None:\n",
    "                    continue\n",
    "                    \n",
    "                similar_sequences = list(self.II.get(element))\n",
    "                \n",
    "                for seq in similar_sequences:\n",
    "                    consequents.append(self.LT.get(seq))\n",
    "                    \n",
    "                count = 0\n",
    "                for consequent in consequents:\n",
    "                    counttable = self.score(counttable,consequent,len(similar_sequences),count)\n",
    "                    count += 1\n",
    "                    \n",
    "                pred = self.get_n_largest(counttable,n)\n",
    "                predictions.append([sequence[0]] + pred)\n",
    "            \"\"\"\n",
    "            \n",
    "            if self.II.get(sequence[1]) is None:\n",
    "                continue\n",
    "                \n",
    "            similar_sequences = list(self.II.get(sequence[1]))\n",
    "            \n",
    "            consequents = [self.LT.get(seq) for seq in similar_sequences]\n",
    "                \n",
    "            count = 0\n",
    "            for consequent in consequents:\n",
    "                counttable = self.score(counttable,consequent,len(similar_sequences),count)\n",
    "                count += 1\n",
    "\n",
    "            pred = self.get_n_largest(counttable,n)\n",
    "            predictions.append([sequence[0]] + pred)\n",
    "            print(num)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def get_n_largest(self,dictionary,n):\n",
    "\n",
    "        \"\"\"\n",
    "        A small utility to obtain top n keys of a Dictionary based on their values.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        largest = sorted(dictionary.items(), key = lambda t: t[1], reverse=True)[:n]\n",
    "        return [key for key,_ in largest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import csv\n",
    "\n",
    "model = CPT()\n",
    "print(\"Started LOADING files at:\", str(datetime.datetime.now()))\n",
    "#\"C:\\\\Users\\\\t-dado\\\\Desktop\\\\TrainTokens\",\"C:\\\\Users\\\\t-dado\\\\Desktop\\\\TestTokens\"\n",
    "#\"C:\\\\Users\\\\t-dado\\\\Desktop\\\\CPT-Others\\\\TrainTokens_Test\",\"C:\\\\Users\\\\t-dado\\\\Desktop\\\\CPT-Others\\\\TestTokens_Test\"\n",
    "data,target = model.load_files(\"C:\\\\Users\\\\t-dado\\\\Desktop\\\\CPT-Others\\\\TrainTokens_Test\",\"C:\\\\Users\\\\t-dado\\\\Desktop\\\\CPT-Others\\\\TestTokens_Test\")\n",
    "print(\"Size of target:\", len(target))\n",
    "print(\"Finished LOADING files at:\", str(datetime.datetime.now()))\n",
    "print(\"Started TRAINING at:\", str(datetime.datetime.now()))\n",
    "model.train(data)\n",
    "print(\"Finished TRAINING at:\", str(datetime.datetime.now()))\n",
    "print(\"Started PREDICTING at:\", str(datetime.datetime.now()))\n",
    "predictions = model.predict(target,5)\n",
    "print(\"Finished PREDICTING at:\", str(datetime.datetime.now()))\n",
    "\n",
    "\"\"\"\n",
    "with open(\"predictions.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(predictions)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
